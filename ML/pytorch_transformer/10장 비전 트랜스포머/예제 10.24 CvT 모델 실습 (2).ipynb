{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e00d6d-5009-4113-b19c-a6aae119bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 10.24 CvT 모델 학습\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor\n",
    "from transformers import CvtForImageClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "def subset_sampler(dataset, classes, max_len):\n",
    "    target_idx = defaultdict(list)\n",
    "    for idx, label in enumerate(dataset.train_labels): \n",
    "        target_idx[int(label)].append(idx)\n",
    "\n",
    "    indices = list(\n",
    "        chain.from_iterable(\n",
    "            [target_idx[idx][:max_len] for idx in range(len(classes))]\n",
    "        )\n",
    "    )\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "def model_init(classes, class_to_idx): \n",
    "    model = CvtForImageClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path = \"microsoft/cvt-21\",\n",
    "        num_labels                    = len(classes),\n",
    "        id2label                      = {idx: label for label, idx in class_to_idx.items()},\n",
    "        label2id                      = class_to_idx,\n",
    "        ignore_mismatched_sizes       = True\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def collator(data, transform):\n",
    "    images, labels = zip(*data)\n",
    "    pixel_values = torch.stack([transform(image) for image in images])\n",
    "    labels       = torch.tensor([label for label in labels])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = evaluate.load(\"f1\")\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    macro_f1    = metric.compute(\n",
    "        predictions = predictions, references = labels, average = \"macro\"\n",
    "    )\n",
    "    return macro_f1\n",
    "\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=\"../datasets\", download=True, train=True)\n",
    "test_dataset  = datasets.FashionMNIST(root=\"../datasets\", download=True, train=False)\n",
    "\n",
    "classes      = train_dataset.classes\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "\n",
    "subset_train_dataset = subset_sampler(\n",
    "    dataset = train_dataset, classes = train_dataset.classes, max_len = 1000\n",
    ")\n",
    "subset_test_dataset = subset_sampler(\n",
    "    dataset = test_dataset, classes = test_dataset.classes, max_len = 100\n",
    ")\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\n",
    "    pretrained_model_name_or_path = \"microsoft/cvt-21\"\n",
    ")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(\n",
    "            size=(\n",
    "                image_processor.size[\"shortest_edge\"],\n",
    "                image_processor.size[\"shortest_edge\"]\n",
    "            )\n",
    "        ),\n",
    "        transforms.Lambda(\n",
    "            lambda x: torch.cat([x, x, x], 0)\n",
    "        ),\n",
    "        transforms.Normalize(\n",
    "            mean = image_processor.image_mean,\n",
    "            std  = image_processor.image_std\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir                  = \"../models/CvT-FashionMNIST\",\n",
    "    save_strategy               = \"epoch\",\n",
    "    evaluation_strategy         = \"epoch\",\n",
    "    learning_rate               = 1e-5,\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size  = 16,\n",
    "    num_train_epochs            = 3,\n",
    "    weight_decay                = 0.001,\n",
    "    load_best_model_at_end      = True,\n",
    "    metric_for_best_model       = \"f1\",\n",
    "    logging_dir                 = \"logs\",\n",
    "    logging_steps               = 125,\n",
    "    remove_unused_columns       = False,\n",
    "    seed                        = 7\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init      = lambda x: model_init(classes, class_to_idx),\n",
    "    args            = args,\n",
    "    train_dataset   = subset_train_dataset,\n",
    "    eval_dataset    = subset_test_dataset,\n",
    "    data_collator   = lambda x: collator(x, transform),\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer       = image_processor,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b878f765",
   "metadata": {},
   "source": [
    "![](../screenshot/cvt1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414c78c",
   "metadata": {},
   "source": [
    "스윈 트랜스포머 모델과 CvT 모델의 F1 점수 결과를 비교했을 때 0.9188에서 0.9209로 소폭 상승"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321b3a8-3aa3-4b76-b447-9547d056705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "outputs = trainer.predict(subset_test_dataset)\n",
    "print(outputs)\n",
    "\n",
    "y_true = outputs.label_ids\n",
    "y_pred = outputs.predictions.argmax(1)\n",
    "\n",
    "labels  = list(classes)\n",
    "matrix  = confusion_matrix(y_true, y_pred)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=labels)\n",
    "_, ax = plt.subplots(figsize=(10, 10))\n",
    "display.plot(xticks_rotation=45, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed471343",
   "metadata": {},
   "source": [
    "![](../screenshot/cvt2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228153a5",
   "metadata": {},
   "source": [
    "ViT 모델과 비교하면 셔츠 카테고리의 오분류가 개선되어 스윈 트랜스포머와 비슷한 성능을 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ee57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PredictionOutput(predictions=array([[ 7.5125170e+00, -9.1174704e-01,  2.1111561e-01, ...,\n",
    "#         -1.1687990e+00, -2.3246503e-01, -1.7586776e+00],\n",
    "#        [ 4.5466981e+00, -1.0524559e-01, -6.1716784e-02, ...,\n",
    "#         -1.2165638e+00, -3.2668003e-01, -1.4728299e+00],\n",
    "#        [ 7.5074434e+00, -1.1107575e+00,  6.4126199e-01, ...,\n",
    "#         -5.3235847e-01, -6.9463331e-01, -1.2789793e+00],\n",
    "#        ...,\n",
    "#        [-1.7925910e+00, -3.0380318e+00, -1.6107290e+00, ...,\n",
    "#          3.0440960e+00,  8.1376545e-04,  5.8561158e+00],\n",
    "#        [ 2.0849815e-01, -2.6135843e+00, -3.7940931e-01, ...,\n",
    "#          1.7778492e+00,  1.8086547e-01,  8.4454737e+00],\n",
    "#        [-3.8607833e-01, -1.7569096e+00, -6.1117899e-01, ...,\n",
    "#          5.1895374e-01, -9.4058156e-02,  7.6384878e+00]], dtype=float32), label_ids=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "#        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
    "#        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "#        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "#        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "#        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "#        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
    "#        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "#        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "#        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "#        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "#        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
    "#        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "#        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "#        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "#        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
    "#        5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "#        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "#        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "#        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "#        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,\n",
    "#        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    "#        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    "#        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    "#        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
    "#        7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
    "#        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
    "#        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
    "#        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
    "#        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
    "#        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "#        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "#        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "#        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
    "#        9, 9, 9, 9, 9, 9, 9, 9, 9, 9]), metrics={'test_loss': 0.24743004143238068, 'test_f1': 0.9209109461529372, 'test_runtime': 8.4411, 'test_samples_per_second': 118.468, 'test_steps_per_second': 7.463})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c22380",
   "metadata": {},
   "source": [
    "|                 | ViT           | Swin Transformer | CvT           |\n",
    "|-----------------|---------------|------------------|---------------|\n",
    "| model size      | 327.325 MB    | 105.227 MB       | 120.791 MB    |\n",
    "| F1-score        | 0.9231        | 0.9159           | 0.9173        | \n",
    "| eval per second | 29.636 eval/s | 58.048 eval/s    | 44.778 eval/s | \n",
    "\n",
    "FashionMNIST 데이터세트에서 비전 트랜스포머 계열 모델은 작은 크기의 학습 데이터세트에서도 높은 정확도와 우수한 성능을 보인다.  \n",
    "가장 일반화 성능이 좋았던 모델은 CvT 모델, 모델 크기 대비 가장 우수한 성능은 Swin Transformer 모델, F1-점수가 가장 높은 모델은 ViT 모델이다.\n",
    "\n",
    "이를 통해 비전 트랜스포머 모델은 분류 문제 해결에 있어 매우 유용한 모델임을 확인할 수 있다. 각각의 모델은 풀어야 하는 문제와 사용처에 따라 적절히 선택한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
